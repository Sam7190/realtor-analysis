{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29661478",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d72cc0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'vars' from 'c:\\\\GitHub\\\\realtor-analysis\\\\vars.py'>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, sys\n",
    "\n",
    "import vars\n",
    "importlib.reload(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "46e10799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier, DMatrix\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d44583d",
   "metadata": {},
   "source": [
    "## Load and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cec817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 3085041 records under Supply Dataset\n",
      "columns:\n",
      "Index(['month_date_yyyymm', 'postal_code', 'zip_name', 'median_listing_price',\n",
      "       'median_listing_price_mm', 'median_listing_price_yy',\n",
      "       'active_listing_count', 'active_listing_count_mm',\n",
      "       'active_listing_count_yy', 'median_days_on_market',\n",
      "       'median_days_on_market_mm', 'median_days_on_market_yy',\n",
      "       'new_listing_count', 'new_listing_count_mm', 'new_listing_count_yy',\n",
      "       'price_increased_count', 'price_increased_count_mm',\n",
      "       'price_increased_count_yy', 'price_increased_share',\n",
      "       'price_increased_share_mm', 'price_increased_share_yy',\n",
      "       'price_reduced_count', 'price_reduced_count_mm',\n",
      "       'price_reduced_count_yy', 'price_reduced_share',\n",
      "       'price_reduced_share_mm', 'price_reduced_share_yy',\n",
      "       'pending_listing_count', 'pending_listing_count_mm',\n",
      "       'pending_listing_count_yy', 'median_listing_price_per_square_foot',\n",
      "       'median_listing_price_per_square_foot_mm',\n",
      "       'median_listing_price_per_square_foot_yy', 'median_square_feet',\n",
      "       'median_square_feet_mm', 'median_square_feet_yy',\n",
      "       'average_listing_price', 'average_listing_price_mm',\n",
      "       'average_listing_price_yy', 'total_listing_count',\n",
      "       'total_listing_count_mm', 'total_listing_count_yy', 'pending_ratio',\n",
      "       'pending_ratio_mm', 'pending_ratio_yy', 'quality_flag'],\n",
      "      dtype='object')\n",
      "Read 1195998 records under Demand Dataset\n",
      "columns:\n",
      "Index(['month_date_yyyymm', 'postal_code', 'zip_name', 'hh_rank',\n",
      "       'hotness_rank', 'hotness_rank_mm', 'hotness_rank_yy', 'hotness_score',\n",
      "       'supply_score', 'demand_score', 'median_days_on_market',\n",
      "       'median_days_on_market_mm', 'median_dom_mm_day',\n",
      "       'median_days_on_market_yy', 'median_dom_yy_day', 'median_dom_vs_us',\n",
      "       'page_view_count_per_property_mm', 'page_view_count_per_property_yy',\n",
      "       'page_view_count_per_property_vs_us', 'median_listing_price',\n",
      "       'median_listing_price_mm', 'median_listing_price_yy',\n",
      "       'median_listing_price_vs_us', 'quality_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "supply = pd.read_csv(vars.supply_data_path)\n",
    "print(f\"Read {len(supply)} records under Supply Dataset\")\n",
    "print('columns:')\n",
    "print(supply.columns)\n",
    "\n",
    "demand = pd.read_csv(vars.demand_data_path)\n",
    "print(f\"Read {len(demand)} records under Demand Dataset\")\n",
    "print('columns:')\n",
    "print(demand.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55739a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postal_code</th>\n",
       "      <th>zip_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56662</td>\n",
       "      <td>outing, mn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24531</td>\n",
       "      <td>chatham, va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26505</td>\n",
       "      <td>morgantown, wv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23838</td>\n",
       "      <td>chesterfield, va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38115</td>\n",
       "      <td>memphis, tn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085036</th>\n",
       "      <td>7826</td>\n",
       "      <td>branchville, nj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085037</th>\n",
       "      <td>29307</td>\n",
       "      <td>spartanburg, sc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085038</th>\n",
       "      <td>84620</td>\n",
       "      <td>aurora, ut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085039</th>\n",
       "      <td>60517</td>\n",
       "      <td>woodridge, il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085040</th>\n",
       "      <td>35089</td>\n",
       "      <td>kellyton, al</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3085041 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         postal_code          zip_name\n",
       "0              56662        outing, mn\n",
       "1              24531       chatham, va\n",
       "2              26505    morgantown, wv\n",
       "3              23838  chesterfield, va\n",
       "4              38115       memphis, tn\n",
       "...              ...               ...\n",
       "3085036         7826   branchville, nj\n",
       "3085037        29307   spartanburg, sc\n",
       "3085038        84620        aurora, ut\n",
       "3085039        60517     woodridge, il\n",
       "3085040        35089      kellyton, al\n",
       "\n",
       "[3085041 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supply[['postal_code', 'zip_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49966231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         zip  county  res_ratio  bus_ratio  oth_ratio  tot_ratio\n",
      "0        606   72093   1.000000   1.000000   1.000000   1.000000\n",
      "1        617   72017   0.969103   0.998428   1.000000   0.971027\n",
      "2        617   72054   0.030897   0.001572   0.000000   0.028973\n",
      "3        674   72145   0.004759   0.017114   0.022523   0.006106\n",
      "4        674   72091   0.995241   0.982886   0.977477   0.993894\n",
      "...      ...     ...        ...        ...        ...        ...\n",
      "53813  99688    2170   1.000000   1.000000   1.000000   1.000000\n",
      "53814  99705    2090   1.000000   1.000000   1.000000   1.000000\n",
      "53815  99694    2170   0.000000   0.000000   1.000000   1.000000\n",
      "53816  99659    2180   0.000000   1.000000   1.000000   1.000000\n",
      "53817  99680    2050   0.000000   0.000000   1.000000   1.000000\n",
      "\n",
      "[53818 rows x 6 columns]\n",
      "Unique Zips (Supply): 34104\n",
      "Unique Zips (Demand): 18777\n",
      "Unique Zips (Crosswalk): 39461\n",
      "Unique County Codes (Crosswalk): 3227\n",
      "Zips in supply/demand not in crosswalk: 33\n"
     ]
    }
   ],
   "source": [
    "zip2county = pd.read_excel(vars.zip2county)\n",
    "print(zip2county)\n",
    "\n",
    "print(f\"Unique Zips (Supply): {supply['postal_code'].nunique()}\")\n",
    "print(f\"Unique Zips (Demand): {demand['postal_code'].nunique()}\")\n",
    "print(f\"Unique Zips (Crosswalk): {zip2county['zip'].nunique()}\")\n",
    "print(f\"Unique County Codes (Crosswalk): {zip2county['county'].nunique()}\")\n",
    "\n",
    "# Check if there are any zips in supply and demand that are not in the crosswalk\n",
    "supply_zips = set(supply['postal_code'].unique())\n",
    "demand_zips = set(demand['postal_code'].unique())\n",
    "crosswalk_zips = set(zip2county['zip'].unique())\n",
    "missing_in_crosswalk = (supply_zips | demand_zips) - crosswalk_zips\n",
    "if missing_in_crosswalk:\n",
    "    print(f\"Zips in supply/demand not in crosswalk: {len(missing_in_crosswalk)}\")\n",
    "else:\n",
    "    print(\"All zips in supply and demand are covered in the crosswalk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "86fc5812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, Supply records: 2033177, Demand records: 1192128\n",
      "Merged records: 1192128, columns: 60\n",
      "['month_date_yyyymm', 'postal_code', 'zip_name', 'median_listing_price', 'median_listing_price_mm', 'median_listing_price_yy', 'active_listing_count', 'active_listing_count_mm', 'active_listing_count_yy', 'median_days_on_market', 'median_days_on_market_mm', 'median_days_on_market_yy', 'new_listing_count', 'new_listing_count_mm', 'new_listing_count_yy', 'price_increased_count', 'price_increased_count_mm', 'price_increased_count_yy', 'price_increased_share', 'price_increased_share_mm', 'price_increased_share_yy', 'price_reduced_count', 'price_reduced_count_mm', 'price_reduced_count_yy', 'price_reduced_share', 'price_reduced_share_mm', 'price_reduced_share_yy', 'pending_listing_count', 'pending_listing_count_mm', 'pending_listing_count_yy', 'median_listing_price_per_square_foot', 'median_listing_price_per_square_foot_mm', 'median_listing_price_per_square_foot_yy', 'median_square_feet', 'median_square_feet_mm', 'median_square_feet_yy', 'average_listing_price', 'average_listing_price_mm', 'average_listing_price_yy', 'total_listing_count', 'total_listing_count_mm', 'total_listing_count_yy', 'pending_ratio', 'pending_ratio_mm', 'pending_ratio_yy', 'quality_flag', 'hh_rank', 'hotness_rank', 'hotness_rank_mm', 'hotness_rank_yy', 'hotness_score', 'supply_score', 'demand_score', 'median_dom_mm_day', 'median_dom_yy_day', 'median_dom_vs_us', 'page_view_count_per_property_mm', 'page_view_count_per_property_yy', 'page_view_count_per_property_vs_us', 'median_listing_price_vs_us']\n"
     ]
    }
   ],
   "source": [
    "# Clean up dataframes such that we only keep records where zip codes are in all three: supply, demand, and crosswalk.\n",
    "zip_intersection = supply_zips & demand_zips & crosswalk_zips\n",
    "sup_df = supply[supply['postal_code'].isin(zip_intersection)].copy()\n",
    "dem_df = demand[demand['postal_code'].isin(zip_intersection)].copy()\n",
    "\n",
    "# Drop Overlapping columns in dem\n",
    "join_keys = ['month_date_yyyymm', 'postal_code']\n",
    "overlap = [c for c in dem_df.columns if c in sup_df.columns and c not in join_keys]\n",
    "\n",
    "# Drop them from demand side before merge\n",
    "dem_df_nodup = dem_df.drop(columns=overlap)\n",
    "\n",
    "# Decision Point: Lets make the decision to only keep zip codes and months that are present in both supply and demand.\n",
    "df = sup_df.merge(dem_df_nodup, 'inner', on=join_keys)\n",
    "\n",
    "print(f\"After cleaning, Supply records: {len(sup_df)}, Demand records: {len(dem_df)}\")\n",
    "print(f\"Merged records: {len(df)}, columns: {len(df.columns)}\")\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b13d44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202507 202506 202505 202504 202503 202502 202501 202412 202411 202410\n",
      " 202409 202408 202407 202406 202405 202404 202403 202402 202401 202312\n",
      " 202311 202310 202309 202308 202307 202306 202305 202304 202303 202302\n",
      " 202301 202212 202211 202210 202209 202208 202207 202206 202205 202204\n",
      " 202203 202202 202201 202112 202111 202110 202109 202108 202107 202106\n",
      " 202105 202104 202103 202102 202101 202012 202011 202010 202009 202008\n",
      " 202007 202006 202005 202004 202003 202002 202001 201912 201911 201910\n",
      " 201909 201908 201907 201906 201905 201904 201903 201902 201901 201812\n",
      " 201811 201810 201809 201808 201807 201806 201805 201804 201803 201802\n",
      " 201801 201712 201711 201710 201709 201708]\n",
      "96\n",
      "    month_count  num_postal_codes\n",
      "0            96              5245\n",
      "1            95               583\n",
      "2            94               456\n",
      "5            93               380\n",
      "6            92               324\n",
      "..          ...               ...\n",
      "15            5               186\n",
      "10            4               256\n",
      "8             3               271\n",
      "4             2               386\n",
      "3             1               402\n",
      "\n",
      "[96 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df['month_date_yyyymm'].unique())\n",
    "print(df['month_date_yyyymm'].nunique())\n",
    "\n",
    "# Group by postal_code and count months\n",
    "counts = df.groupby('postal_code')['month_date_yyyymm'].nunique().reset_index()\n",
    "\n",
    "# Rename for clarity\n",
    "counts = counts.rename(columns={'month_date_yyyymm': 'month_count'})\n",
    "\n",
    "# Now group by month_count and count how often each occurs\n",
    "distribution = counts['month_count'].value_counts().reset_index()\n",
    "distribution.columns = ['month_count', 'num_postal_codes']\n",
    "distribution = distribution.sort_values('month_count', ascending=False)\n",
    "\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "83723f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of result: 857566\n",
      "Index([ 1056,  1085,  1095,  1109,  1201,  1230,  1247,  1267,  1331,  1420,\n",
      "       ...\n",
      "       99645, 99654, 99669, 99688, 99705, 99709, 99712, 99737, 99801, 99901],\n",
      "      dtype='int64', name='postal_code', length=9297)\n",
      "Length of 92620: 94\n",
      "Length of 99645: 96\n",
      "month\n",
      "36    7796\n",
      "35     513\n",
      "34     395\n",
      "33     330\n",
      "32     263\n",
      "31     259\n",
      "30     216\n",
      "29     211\n",
      "28     185\n",
      "27     177\n",
      "26     155\n",
      "25     180\n",
      "24     158\n",
      "23     137\n",
      "22     141\n",
      "21     144\n",
      "20     166\n",
      "19     136\n",
      "18     148\n",
      "17     138\n",
      "16     132\n",
      "15     164\n",
      "14     151\n",
      "13     174\n",
      "12     159\n",
      "11     159\n",
      "10     143\n",
      "9      168\n",
      "8      210\n",
      "7      173\n",
      "6      215\n",
      "5      224\n",
      "4      263\n",
      "3      349\n",
      "2      434\n",
      "1      522\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Anchor and required 36-month window [2025-07, 2025-06, ..., 2022-08]\n",
    "anchor = pd.Period(vars.start_date, freq='M')\n",
    "last_date = pd.Period(vars.end_date, freq='M')\n",
    "required_months = {anchor - i for i in range(vars.check_window_months)}  # set for fast membership\n",
    "\n",
    "# Add a Period month column\n",
    "df2 = df.copy()\n",
    "df2['month'] = pd.to_datetime(df['month_date_yyyymm'], format='%Y%m').dt.to_period('M')\n",
    "\n",
    "# Keep only rows in the required 36-month window\n",
    "df_win = df2[df2['month'].isin(required_months)]\n",
    "\n",
    "# Count distinct months per postal_code within the window\n",
    "counts = df_win.groupby('postal_code')['month'].nunique()\n",
    "\n",
    "# Postal codes with all vars.min_records months present (consecutive by construction of the window)\n",
    "valid_postals = counts[counts >= vars.min_acceptable_records].index\n",
    "\n",
    "# Final result: only those postal_codes and only those 36 months\n",
    "final_df = (\n",
    "    df2[\n",
    "        (df2['postal_code'].isin(valid_postals)) &\n",
    "        (df2['month'] >= last_date)]\n",
    "    .sort_values(['postal_code', 'month'], ascending=[True, False])\n",
    ")\n",
    "\n",
    "# quick summary\n",
    "print(f\"Len of result: {len(final_df)}\")\n",
    "print(valid_postals)\n",
    "print(f\"Length of 92620: {len(final_df[final_df['postal_code'] == 92620])}\")\n",
    "print(f\"Length of 99645: {len(final_df[final_df['postal_code'] == 99645])}\")\n",
    "summary = counts.value_counts().sort_index(ascending=False)\n",
    "print(summary)  # how many postal_codes have 36, 35, ..., months present in the window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68277e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Zips (Supply): 34104\n",
      "Unique Zips (Demand): 18777\n",
      "Unique Zips (Full DF): 9297\n",
      "DF Columns: Index(['month_date_yyyymm', 'postal_code', 'zip_name', 'median_listing_price',\n",
      "       'median_listing_price_mm', 'median_listing_price_yy',\n",
      "       'active_listing_count', 'active_listing_count_mm',\n",
      "       'active_listing_count_yy', 'median_days_on_market',\n",
      "       'median_days_on_market_mm', 'median_days_on_market_yy',\n",
      "       'new_listing_count', 'new_listing_count_mm', 'new_listing_count_yy',\n",
      "       'price_increased_count', 'price_increased_count_mm',\n",
      "       'price_increased_count_yy', 'price_increased_share',\n",
      "       'price_increased_share_mm', 'price_increased_share_yy',\n",
      "       'price_reduced_count', 'price_reduced_count_mm',\n",
      "       'price_reduced_count_yy', 'price_reduced_share',\n",
      "       'price_reduced_share_mm', 'price_reduced_share_yy',\n",
      "       'pending_listing_count', 'pending_listing_count_mm',\n",
      "       'pending_listing_count_yy', 'median_listing_price_per_square_foot',\n",
      "       'median_listing_price_per_square_foot_mm',\n",
      "       'median_listing_price_per_square_foot_yy', 'median_square_feet',\n",
      "       'median_square_feet_mm', 'median_square_feet_yy',\n",
      "       'average_listing_price', 'average_listing_price_mm',\n",
      "       'average_listing_price_yy', 'total_listing_count',\n",
      "       'total_listing_count_mm', 'total_listing_count_yy', 'pending_ratio',\n",
      "       'pending_ratio_mm', 'pending_ratio_yy', 'quality_flag', 'hh_rank',\n",
      "       'hotness_rank', 'hotness_rank_mm', 'hotness_rank_yy', 'hotness_score',\n",
      "       'supply_score', 'demand_score', 'median_dom_mm_day',\n",
      "       'median_dom_yy_day', 'median_dom_vs_us',\n",
      "       'page_view_count_per_property_mm', 'page_view_count_per_property_yy',\n",
      "       'page_view_count_per_property_vs_us', 'median_listing_price_vs_us',\n",
      "       'month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Lets get a sense for how many zip-codes we have thrown out after the cleaning process from both the supply and demand.\n",
    "print(f\"Unique Zips (Supply): {supply['postal_code'].nunique()}\")\n",
    "print(f\"Unique Zips (Demand): {demand['postal_code'].nunique()}\")\n",
    "print(f\"Unique Zips (Full DF): {final_df['postal_code'].nunique()}\")\n",
    "print(f\"DF Columns: {final_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8bfed6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6059] 86 7271 157\n",
      "['month_date_yyyymm', 'postal_code', 'zip_name_sup', 'median_listing_price_sup', 'median_listing_price_mm_sup', 'median_listing_price_yy_sup', 'active_listing_count', 'active_listing_count_mm', 'active_listing_count_yy', 'median_days_on_market_sup', 'median_days_on_market_mm_sup', 'median_days_on_market_yy_sup', 'new_listing_count', 'new_listing_count_mm', 'new_listing_count_yy', 'price_increased_count', 'price_increased_count_mm', 'price_increased_count_yy', 'price_increased_share', 'price_increased_share_mm', 'price_increased_share_yy', 'price_reduced_count', 'price_reduced_count_mm', 'price_reduced_count_yy', 'price_reduced_share', 'price_reduced_share_mm', 'price_reduced_share_yy', 'pending_listing_count', 'pending_listing_count_mm', 'pending_listing_count_yy', 'median_listing_price_per_square_foot', 'median_listing_price_per_square_foot_mm', 'median_listing_price_per_square_foot_yy', 'median_square_feet', 'median_square_feet_mm', 'median_square_feet_yy', 'average_listing_price', 'average_listing_price_mm', 'average_listing_price_yy', 'total_listing_count', 'total_listing_count_mm', 'total_listing_count_yy', 'pending_ratio', 'pending_ratio_mm', 'pending_ratio_yy', 'quality_flag_sup', 'zip_name_dem', 'hh_rank', 'hotness_rank', 'hotness_rank_mm', 'hotness_rank_yy', 'hotness_score', 'supply_score', 'demand_score', 'median_days_on_market_dem', 'median_days_on_market_mm_dem', 'median_dom_mm_day', 'median_days_on_market_yy_dem', 'median_dom_yy_day', 'median_dom_vs_us', 'page_view_count_per_property_mm', 'page_view_count_per_property_yy', 'page_view_count_per_property_vs_us', 'median_listing_price_dem', 'median_listing_price_mm_dem', 'median_listing_price_yy_dem', 'median_listing_price_vs_us', 'quality_flag_dem', 'zip', 'county', 'original_zip', 'zip_92672', 'zip_92673', 'zip_92675', 'zip_92676', 'zip_92677', 'zip_90630', 'zip_90631', 'zip_92679', 'zip_92683', 'zip_90638', 'zip_92688', 'zip_92691', 'zip_92692', 'zip_92694', 'zip_92701', 'zip_92703', 'zip_92704', 'zip_92705', 'zip_92706', 'zip_92707', 'zip_92708', 'zip_90680', 'zip_90720', 'zip_92780', 'zip_92782', 'zip_90740', 'zip_92801', 'zip_92802', 'zip_92804', 'zip_92805', 'zip_92806', 'zip_92807', 'zip_92808', 'zip_92821', 'zip_92823', 'zip_92831', 'zip_92832', 'zip_92833', 'zip_92835', 'zip_92840', 'zip_92841', 'zip_92843', 'zip_92844', 'zip_92845', 'zip_90808', 'zip_92861', 'zip_90815', 'zip_92865', 'zip_92866', 'zip_92867', 'zip_92868', 'zip_92869', 'zip_92870', 'zip_92886', 'zip_92887', 'zip_92602', 'zip_92603', 'zip_92604', 'zip_92606', 'zip_92610', 'zip_92612', 'zip_92614', 'zip_92618', 'zip_92620', 'zip_92624', 'zip_92625', 'zip_92626', 'zip_92627', 'zip_92629', 'zip_92630', 'zip_92637', 'zip_92646', 'zip_92647', 'zip_92648', 'zip_92649', 'zip_92651', 'zip_92653', 'zip_92656', 'zip_92657', 'zip_92660', 'zip_92661', 'zip_92662', 'zip_92663', 'zip_90620', 'zip_90621', 'zip_90623']\n"
     ]
    }
   ],
   "source": [
    "# Experimenting with grab_records function build\n",
    "zips = [92620]\n",
    "counties = zip2county[zip2county['zip'].isin(zips)]['county'].unique()\n",
    "all_zips = zip2county[zip2county['county'].isin(counties)]['zip'].unique()\n",
    "Z = list(set(all_zips).intersection(zip_intersection))\n",
    "postal_df = df[df['postal_code'].isin(Z)]\n",
    "postal_df.loc[:, 'original_zip'] = postal_df['postal_code'].isin(zips).astype(int)\n",
    "for z in Z:\n",
    "    postal_df.loc[:, f'zip_{z}'] = (postal_df['postal_code'] == z).astype(int)\n",
    "print(counties, len(Z), len(postal_df), len(postal_df.columns))\n",
    "print(postal_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6400a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_county_records(df, zips, zip2county=zip2county):\n",
    "    counties = zip2county[zip2county['zip'].isin(zips)]['county'].unique()\n",
    "    all_zips = zip2county[zip2county['county'].isin(counties)]['zip'].unique()\n",
    "    Z = list(set(all_zips).intersection(zip_intersection))\n",
    "    postal_df = df[df['postal_code'].isin(Z)]\n",
    "    postal_df.loc[:, 'original_zip'] = postal_df['postal_code'].isin(zips).astype(int)\n",
    "    for z in Z:\n",
    "        postal_df.loc[:, f'zip_{z}'] = (postal_df['postal_code'] == z).astype(int)\n",
    "    return postal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f233eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_training_records(final_df, zip, outcome_thresholds=vars.outcome_thresholds):\n",
    "    postal_df = final_df[final_df['postal_code'] == zip].reset_index(0).drop(columns=['index'])\n",
    "    training_sets = {i: [] for i in range(1, vars.max_months_predicted + 1)}\n",
    "    outcome_sets = {i: [] for i in range(1, vars.max_months_predicted + 1)}\n",
    "    appended = {i: 0 for i in range(1, vars.max_months_predicted + 1)}\n",
    "\n",
    "    outcome_trend = postal_df[['month']].copy().reset_index(drop=True).iloc[:-1]\n",
    "\n",
    "    price_after = postal_df['median_listing_price'].iloc[:-1].to_numpy()\n",
    "    price_before = postal_df['median_listing_price'].iloc[1:].to_numpy()\n",
    "    price_ratio = (price_after - price_before) / price_before\n",
    "    outcome_trend['price_change'] = price_ratio\n",
    "\n",
    "    outcome_trend['days_on_market'] = postal_df['median_days_on_market'].iloc[:-1].to_numpy()\n",
    "\n",
    "    count_after = postal_df['page_view_count_per_property_vs_us'].iloc[:-1].to_numpy()\n",
    "    count_before = postal_df['page_view_count_per_property_vs_us'].iloc[1:].to_numpy()\n",
    "    count_ratio = (count_after - count_before) / count_before\n",
    "    outcome_trend['view_count_change'] = count_ratio\n",
    "\n",
    "    for i in range(len(postal_df)):\n",
    "        for t in training_sets:\n",
    "            j = i + t\n",
    "            if j >= len(postal_df):\n",
    "                continue\n",
    "\n",
    "            # Get how many months the two records are separted by\n",
    "            months_sep = postal_df.loc[i, 'month'] - postal_df.loc[j, 'month']\n",
    "            months_int = months_sep.n\n",
    "            if (months_int > vars.max_months_predicted):\n",
    "                continue\n",
    "            elif months_int < 1:\n",
    "                raise AssertionError(f\"Somehow months_int < 1 for {i}, {j}, {months_int}\")\n",
    "\n",
    "            # Calculate Price Outcomes\n",
    "            price_before = postal_df.loc[i, 'median_listing_price']\n",
    "            price_after = postal_df.loc[j, 'median_listing_price']\n",
    "            price_ratio = (price_after - price_before) / price_before\n",
    "\n",
    "            high_risk_price = int(price_ratio <= outcome_thresholds['high_risk']['price_change'])\n",
    "            strong_market_price = int(price_ratio >= outcome_thresholds['strong_market']['price_change'])\n",
    "\n",
    "            # Calculate Day on Market Outcomes\n",
    "            dom_after = postal_df.loc[j, 'median_days_on_market']\n",
    "\n",
    "            high_risk_dom = int(dom_after >= outcome_thresholds['high_risk']['days_on_market'])\n",
    "            strong_market_dom = int(dom_after <= outcome_thresholds['strong_market']['days_on_market'])\n",
    "\n",
    "            # Calculate View Count Outcomes\n",
    "            count_before = postal_df.loc[i, 'page_view_count_per_property_vs_us']\n",
    "            count_after = postal_df.loc[j, 'page_view_count_per_property_vs_us']\n",
    "            count_ratio = (count_after - count_before) / count_before\n",
    "\n",
    "            high_risk_count = int(count_ratio <= outcome_thresholds['high_risk']['view_count_change'])\n",
    "            strong_market_count = int(count_ratio >= outcome_thresholds['strong_market']['view_count_change'])\n",
    "\n",
    "            # Append to training and outcome sets\n",
    "            training_sets[months_int].append(postal_df.loc[j, vars.features].to_numpy())\n",
    "            outcome_sets[months_int].append([high_risk_price, strong_market_price,\n",
    "                                             high_risk_dom, strong_market_dom,\n",
    "                                             high_risk_count, strong_market_count])\n",
    "            appended[months_int] += 1\n",
    "    \n",
    "    inference_point = np.array([postal_df.loc[0, vars.features].to_numpy()])\n",
    "    for t in training_sets:\n",
    "        training_sets[t] = np.array(training_sets[t])\n",
    "        outcome_sets[t] = np.array(outcome_sets[t])\n",
    "\n",
    "    return training_sets, outcome_sets, outcome_trend, inference_point\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cdf3c4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 91 91 56 6\n",
      "2 90 90 56 6\n",
      "3 89 89 56 6\n",
      "4 88 88 56 6\n",
      "5 87 87 56 6\n",
      "6 86 86 56 6\n",
      "7 85 85 56 6\n",
      "8 84 84 56 6\n",
      "9 83 83 56 6\n",
      "10 82 82 56 6\n",
      "11 81 81 56 6\n",
      "12 80 80 56 6\n",
      "      month  price_change  days_on_market  view_count_change\n",
      "0   2025-07     -0.005528            53.0          -0.051592\n",
      "1   2025-06     -0.008094            44.0          -0.147356\n",
      "2   2025-05     -0.014918            41.0          -0.214539\n",
      "3   2025-04      0.062876            36.0           0.023604\n",
      "4   2025-03      0.060597            26.0          -0.047027\n",
      "..      ...           ...             ...                ...\n",
      "88  2018-01      0.039629            35.0          -0.020748\n",
      "89  2017-12      0.009988            44.0           0.278732\n",
      "90  2017-11      0.122298            36.0          -0.020796\n",
      "91  2017-10      0.003147            34.0           0.083764\n",
      "92  2017-09     -0.034875            31.0           0.049489\n",
      "\n",
      "[93 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "zip = 92620\n",
    "training_sets, outcome_sets, outcome_trend, inference_point = grab_training_records(final_df, zip)\n",
    "for t in training_sets:\n",
    "    print(t, len(training_sets[t]), len(outcome_sets[t]), len(training_sets[t][0]), len(outcome_sets[t][0]))\n",
    "\n",
    "print(outcome_trend)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2b2ffe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month  price_change  days_on_market  view_count_change\n",
      "0  2025-08-01      0.030263       29.602907          -0.084367\n",
      "1  2025-09-01      0.001926       33.215659          -0.034709\n",
      "2  2025-10-01     -0.012744       37.183797           0.023847\n",
      "3  2025-11-01      0.005887       38.465034           0.044645\n",
      "4  2025-12-01      0.009730       41.411805           0.064530\n",
      "5  2026-01-01     -0.008759       46.373143           0.093796\n",
      "6  2026-02-01      0.004418       45.154970           0.066239\n",
      "7  2026-03-01      0.049048       35.601929          -0.027098\n",
      "8  2026-04-01      0.055040       27.949649          -0.087720\n",
      "9  2026-05-01      0.011627       28.870069          -0.067316\n",
      "10 2026-06-01     -0.008129       31.754612          -0.044343\n",
      "11 2026-07-01      0.019416       30.368441          -0.072361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def forecast_12_fourier(outcome_trend, horizon=12, K=3, period=12):\n",
    "    df = outcome_trend.copy()\n",
    "\n",
    "    # --- normalize month to Timestamp at month-start ---\n",
    "    m = df['month']\n",
    "    if pd.api.types.is_period_dtype(m):\n",
    "        # Coerce to monthly periods and convert to timestamps (start of month)\n",
    "        df['month'] = pd.PeriodIndex(m, freq='M').to_timestamp()  # <-- no 'MS' here\n",
    "    elif pd.api.types.is_datetime64_any_dtype(m):\n",
    "        df['month'] = m.dt.to_period('M').dt.to_timestamp()\n",
    "    else:\n",
    "        df['month'] = pd.to_datetime(m, errors='coerce').dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "    df = df.sort_values('month').reset_index(drop=True)\n",
    "\n",
    "    # time index\n",
    "    t = np.arange(len(df))\n",
    "    t_future = np.arange(len(df), len(df) + horizon)\n",
    "\n",
    "    def fourier_basis(tt, K, period):\n",
    "        X = [np.ones_like(tt), tt]  # intercept + linear trend\n",
    "        for k in range(1, K + 1):\n",
    "            X.append(np.sin(2 * np.pi * k * tt / period))\n",
    "            X.append(np.cos(2 * np.pi * k * tt / period))\n",
    "        return np.column_stack(X)\n",
    "\n",
    "    X  = fourier_basis(t, K, period)\n",
    "    Xf = fourier_basis(t_future, K, period)\n",
    "\n",
    "    target_cols = ['price_change', 'days_on_market', 'view_count_change']\n",
    "    preds = {}\n",
    "\n",
    "    for col in target_cols:\n",
    "        y = df[col].astype(float).to_numpy()\n",
    "        model = Ridge(alpha=1.0)\n",
    "        model.fit(X, y)\n",
    "        yhat = model.predict(Xf)\n",
    "        if col == 'days_on_market':\n",
    "            yhat = np.clip(yhat, 0, None)\n",
    "        preds[col] = yhat\n",
    "\n",
    "    future_months = pd.date_range(df['month'].iloc[-1] + pd.offsets.MonthBegin(1),\n",
    "                                  periods=horizon, freq='MS')\n",
    "    out = pd.DataFrame({'month': future_months})\n",
    "    for col in target_cols:\n",
    "        out[col] = preds[col]\n",
    "    return out\n",
    "\n",
    "\n",
    "# usage:\n",
    "future_12 = forecast_12_fourier(outcome_trend, horizon=12, K=3)\n",
    "print(future_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6f061bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              series       RMSE  RMSE_baseline  RMSE_improvement_%  \\\n",
      "1     days_on_market  16.345059      19.283580           15.238462   \n",
      "0       price_change   0.069273       0.083718           17.253702   \n",
      "2  view_count_change   0.140987       0.233121           39.522080   \n",
      "\n",
      "      sMAPE_%  sMAPE_baseline_%  sMAPE_improvement_%      MASE  MASE_baseline  \n",
      "1   39.446466         45.972967            14.196388  1.123391       1.200344  \n",
      "0  141.916400        154.604815             8.206999  1.055244       1.379221  \n",
      "2  130.571404        156.289588            16.455469  0.908872       1.492491  \n",
      "    horizon  mean_abs_error\n",
      "0         1        0.048155\n",
      "1         2        0.046980\n",
      "2         3        0.046670\n",
      "3         4        0.049525\n",
      "4         5        0.050771\n",
      "5         6        0.051534\n",
      "6         7        0.047543\n",
      "7         8        0.048029\n",
      "8         9        0.045594\n",
      "9        10        0.046935\n",
      "10       11        0.046089\n",
      "11       12        0.046103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2435378718.py:10: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- metrics ----------\n",
    "def rmse(y, yhat):\n",
    "    return float(np.sqrt(np.mean((y - yhat) ** 2)))\n",
    "\n",
    "def smape(y, yhat, eps=1e-8):\n",
    "    num = np.abs(y - yhat)\n",
    "    den = (np.abs(y) + np.abs(yhat) + eps) / 2.0\n",
    "    return float(100 * np.mean(num / den))  # percent\n",
    "\n",
    "def mase(y_true, y_pred, y_train, m=12):\n",
    "    # scale by seasonal naive MAE on the *training* period\n",
    "    if len(y_train) <= m:\n",
    "        return np.nan\n",
    "    denom = np.mean(np.abs(y_train[m:] - y_train[:-m]))\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    return float(np.mean(np.abs(y_true - y_pred)) / denom)\n",
    "\n",
    "# ---------- month normalization ----------\n",
    "def _normalize_month_index(df):\n",
    "    d = df.copy()\n",
    "    m = d['month']\n",
    "    if pd.api.types.is_period_dtype(m):\n",
    "        d['month'] = pd.PeriodIndex(m, freq='M').to_timestamp()\n",
    "    elif pd.api.types.is_datetime64_any_dtype(m):\n",
    "        d['month'] = m.dt.to_period('M').dt.to_timestamp()\n",
    "    else:\n",
    "        d['month'] = pd.to_datetime(m, errors='coerce').dt.to_period('M').dt.to_timestamp()\n",
    "    d = d.sort_values('month').set_index('month')\n",
    "    return d\n",
    "\n",
    "# ---------- backtester ----------\n",
    "def backtest_forecaster(outcome_trend, forecaster, horizon=12, seasonality=12, min_train=36, step=1):\n",
    "    \"\"\"\n",
    "    forecaster: function(train_df, horizon) -> DataFrame with 'month' and same numeric columns\n",
    "    \"\"\"\n",
    "    df = _normalize_month_index(outcome_trend)\n",
    "    cols = [c for c in df.columns if c != 'month']  # index now holds month\n",
    "    n = len(df)\n",
    "    cut_starts = list(range(min_train-1, n - horizon, step))  # index of last training obs\n",
    "\n",
    "    # collectors\n",
    "    per_h_metrics = {c: {h+1: [] for h in range(horizon)} for c in cols}\n",
    "    overall = {c: {\"RMSE\": [], \"sMAPE\": [], \"MASE\": [], \"RMSE_baseline\": [], \"sMAPE_baseline\": [], \"MASE_baseline\": []} for c in cols}\n",
    "\n",
    "    for cut in cut_starts:\n",
    "        train = df.iloc[:cut+1].copy()\n",
    "        future_idx = pd.date_range(train.index[-1] + pd.offsets.MonthBegin(1), periods=horizon, freq='MS')\n",
    "\n",
    "        # model forecast\n",
    "        fcast = forecaster(train.reset_index().rename(columns={'index': 'month'}), horizon=horizon)\n",
    "        fcast = _normalize_month_index(fcast).reindex(future_idx)\n",
    "\n",
    "        # actuals\n",
    "        truth = df.iloc[cut+1:cut+1+horizon].reindex(future_idx)\n",
    "\n",
    "        # seasonal naive baseline: y_{t+h} = y_{t+h-12}\n",
    "        baseline = df[cols].shift(seasonality).iloc[cut+1:cut+1+horizon].reindex(future_idx)\n",
    "\n",
    "        # compute metrics per column\n",
    "        for c in cols:\n",
    "            y_true = truth[c].astype(float).to_numpy()\n",
    "            y_hat  = fcast[c].astype(float).to_numpy()\n",
    "            y_base = baseline[c].astype(float).to_numpy()\n",
    "\n",
    "            mask_model = ~np.isnan(y_true) & ~np.isnan(y_hat)\n",
    "            mask_base  = ~np.isnan(y_true) & ~np.isnan(y_base)\n",
    "\n",
    "            if mask_model.any():\n",
    "                overall[c][\"RMSE\"].append(rmse(y_true[mask_model], y_hat[mask_model]))\n",
    "                overall[c][\"sMAPE\"].append(smape(y_true[mask_model], y_hat[mask_model]))\n",
    "                # MASE needs training history of this column\n",
    "                overall[c][\"MASE\"].append(mase(y_true[mask_model], y_hat[mask_model], train[c].astype(float).to_numpy(), m=seasonality))\n",
    "                # per-horizon\n",
    "                for h in range(horizon):\n",
    "                    if not np.isnan(y_true[h]) and not np.isnan(y_hat[h]):\n",
    "                        per_h_metrics[c][h+1].append(abs(y_true[h]-y_hat[h]))\n",
    "\n",
    "            if mask_base.any():\n",
    "                overall[c][\"RMSE_baseline\"].append(rmse(y_true[mask_base], y_base[mask_base]))\n",
    "                overall[c][\"sMAPE_baseline\"].append(smape(y_true[mask_base], y_base[mask_base]))\n",
    "                overall[c][\"MASE_baseline\"].append(mase(y_true[mask_base], y_base[mask_base], train[c].astype(float).to_numpy(), m=seasonality))\n",
    "\n",
    "    # aggregate\n",
    "    rows = []\n",
    "    for c in cols:\n",
    "        if overall[c][\"RMSE\"]:\n",
    "            rmse_m   = np.mean(overall[c][\"RMSE\"])\n",
    "            rmse_b   = np.mean(overall[c][\"RMSE_baseline\"]) if overall[c][\"RMSE_baseline\"] else np.nan\n",
    "            smape_m  = np.mean(overall[c][\"sMAPE\"])\n",
    "            smape_b  = np.mean(overall[c][\"sMAPE_baseline\"]) if overall[c][\"sMAPE_baseline\"] else np.nan\n",
    "            mase_m   = np.nanmean(overall[c][\"MASE\"])\n",
    "            mase_b   = np.nanmean(overall[c][\"MASE_baseline\"]) if overall[c][\"MASE_baseline\"] else np.nan\n",
    "            rows.append({\n",
    "                \"series\": c,\n",
    "                \"RMSE\": rmse_m,\n",
    "                \"RMSE_baseline\": rmse_b,\n",
    "                \"RMSE_improvement_%\": (1 - rmse_m/rmse_b)*100 if rmse_b and rmse_b>0 else np.nan,\n",
    "                \"sMAPE_%\": smape_m,\n",
    "                \"sMAPE_baseline_%\": smape_b,\n",
    "                \"sMAPE_improvement_%\": (1 - smape_m/smape_b)*100 if smape_b and smape_b>0 else np.nan,\n",
    "                \"MASE\": mase_m,               # <1 means better than seasonal naive\n",
    "                \"MASE_baseline\": mase_b       # ~1 for seasonal naive\n",
    "            })\n",
    "\n",
    "    summary = pd.DataFrame(rows).sort_values(\"series\")\n",
    "\n",
    "    # Optional: mean absolute error by forecast horizon (useful to see decay)\n",
    "    by_horizon = {}\n",
    "    for c in cols:\n",
    "        by_horizon[c] = pd.DataFrame({\n",
    "            \"horizon\": list(per_h_metrics[c].keys()),\n",
    "            \"mean_abs_error\": [np.mean(per_h_metrics[c][h]) if per_h_metrics[c][h] else np.nan\n",
    "                               for h in per_h_metrics[c]]\n",
    "        })\n",
    "\n",
    "    return summary, by_horizon\n",
    "\n",
    "# your forecaster (wraps the function you already have)\n",
    "def fourier_forecaster(train_df, horizon):\n",
    "    return forecast_12_fourier(train_df, horizon=horizon, K=3, period=12)\n",
    "\n",
    "summary, by_h = backtest_forecaster(outcome_trend, forecaster=fourier_forecaster,\n",
    "                                    horizon=12, seasonality=12, min_train=36, step=1)\n",
    "print(summary)                 # overall metrics vs seasonal naive\n",
    "print(by_h['price_change'])    # error by horizon for a specific series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b38903b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        month  price_change  days_on_market  view_count_change\n",
      "0  2025-08-01      0.019507       49.288494          -0.015636\n",
      "1  2025-09-01     -0.027931       46.054058           0.003950\n",
      "2  2025-10-01     -0.000581       45.142601          -0.019385\n",
      "3  2025-11-01     -0.016734       60.664890           0.075709\n",
      "4  2025-12-01     -0.024842       66.730011           0.022362\n",
      "5  2026-01-01      0.021792       58.692070          -0.021615\n",
      "6  2026-02-01      0.008189       46.484100          -0.021890\n",
      "7  2026-03-01      0.001586       37.830471          -0.005836\n",
      "8  2026-04-01     -0.006501       36.096016          -0.047094\n",
      "9  2026-05-01     -0.006828       40.076237          -0.066617\n",
      "10 2026-06-01      0.038745       46.827927          -0.063030\n",
      "11 2026-07-01      0.047669       48.941154          -0.041157\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "def forecast_12_xgb(outcome_trend, horizon=12, use_gpu=False, max_lag=12,\n",
    "                    add_calendar=True, params=None, nonneg_cols=(\"days_on_market\",)):\n",
    "    \"\"\"\n",
    "    Forecast next `horizon` months for each numeric column except 'month'\n",
    "    using XGBoost with lag/rolling features (univariate per series).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    outcome_trend : pd.DataFrame\n",
    "        Must contain a 'month' column and â‰¥1 numeric series columns.\n",
    "    horizon : int\n",
    "        Number of months to forecast.\n",
    "    use_gpu : bool\n",
    "        If True, try to use GPU (falls back to CPU if unavailable).\n",
    "    max_lag : int\n",
    "        Maximum number of monthly lags to include (auto-reduced if history is short).\n",
    "    add_calendar : bool\n",
    "        If True, add month-of-year sin/cos features.\n",
    "    params : dict or None\n",
    "        Extra/override XGBRegressor params.\n",
    "    nonneg_cols : tuple of str\n",
    "        Columns to clip at [0, âˆž) after prediction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame with 'month' and one column per input series (forecasts).\n",
    "    \"\"\"\n",
    "\n",
    "    def _normalize_month_index(df):\n",
    "        d = df.copy()\n",
    "        m = d[\"month\"]\n",
    "        if pd.api.types.is_period_dtype(m):\n",
    "            d[\"month\"] = pd.PeriodIndex(m, freq=\"M\").to_timestamp()\n",
    "        elif pd.api.types.is_datetime64_any_dtype(m):\n",
    "            d[\"month\"] = m.dt.to_period(\"M\").dt.to_timestamp()\n",
    "        else:\n",
    "            d[\"month\"] = pd.to_datetime(m, errors=\"coerce\").dt.to_period(\"M\").dt.to_timestamp()\n",
    "        d = d.sort_values(\"month\").set_index(\"month\")\n",
    "        return d\n",
    "\n",
    "    df = _normalize_month_index(outcome_trend)\n",
    "\n",
    "    # choose numeric cols except 'month'\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not num_cols:\n",
    "        raise ValueError(\"No numeric columns to forecast. Ensure you have numeric series columns in addition to 'month'.\")\n",
    "\n",
    "    # base XGB params\n",
    "    xgb_params = dict(\n",
    "        n_estimators=500,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=0,\n",
    "        objective=\"reg:squarederror\",\n",
    "    )\n",
    "\n",
    "    # GPU toggle\n",
    "    if use_gpu:\n",
    "        try:\n",
    "            import xgboost as xgb\n",
    "            from packaging.version import Version\n",
    "            if Version(xgb.__version__) >= Version(\"2.0.0\"):\n",
    "                xgb_params.update(tree_method=\"hist\", device=\"cuda\")\n",
    "            else:\n",
    "                xgb_params.update(tree_method=\"gpu_hist\", predictor=\"gpu_predictor\")\n",
    "        except Exception:\n",
    "            # fall back silently to CPU\n",
    "            pass\n",
    "\n",
    "    if params:\n",
    "        xgb_params.update(params)\n",
    "\n",
    "    # helper to build supervised frame for one series\n",
    "    def _make_supervised(series: pd.Series, L: int):\n",
    "        s = series.astype(float).copy()\n",
    "\n",
    "        parts = []\n",
    "        # lags 1..L\n",
    "        for l in range(1, L + 1):\n",
    "            parts.append(s.shift(l).rename(f\"lag_{l}\"))\n",
    "\n",
    "        # rolling means based on prior values\n",
    "        parts.append(s.shift(1).rolling(3, min_periods=1).mean().rename(\"roll3\"))\n",
    "        parts.append(s.shift(1).rolling(6, min_periods=1).mean().rename(\"roll6\"))\n",
    "        parts.append(s.shift(1).rolling(12, min_periods=1).mean().rename(\"roll12\"))\n",
    "\n",
    "        if add_calendar:\n",
    "            # month-of-year sin/cos (align with current timestamp rows)\n",
    "            idx = s.index\n",
    "            month_num = idx.month.values  # 1..12\n",
    "            # convert to series aligned with index\n",
    "            mo = pd.Series(month_num, index=idx)\n",
    "            parts.append(np.sin(2 * np.pi * mo / 12).rename(\"mo_sin\"))\n",
    "            parts.append(np.cos(2 * np.pi * mo / 12).rename(\"mo_cos\"))\n",
    "\n",
    "        X = pd.concat(parts, axis=1)\n",
    "        y = s\n",
    "        data = pd.concat([X, y.rename(\"y\")], axis=1).dropna()\n",
    "        return data.drop(columns=[\"y\"]), data[\"y\"]\n",
    "\n",
    "    forecasts = {}\n",
    "    last_month = df.index[-1]\n",
    "    future_idx = pd.date_range(last_month + pd.offsets.MonthBegin(1), periods=horizon, freq=\"MS\")\n",
    "\n",
    "    for col in num_cols:\n",
    "        s = df[col].astype(float)\n",
    "        if len(s) < 3:\n",
    "            # too short; repeat last value\n",
    "            forecasts[col] = pd.Series([float(s.iloc[-1])] * horizon, index=future_idx)\n",
    "            continue\n",
    "\n",
    "        L = max(1, min(max_lag, len(s) - 1))\n",
    "        X, y = _make_supervised(s, L)\n",
    "\n",
    "        # keep feature order for recursive steps\n",
    "        feature_order = X.columns.tolist()\n",
    "\n",
    "        model = XGBRegressor(**xgb_params)\n",
    "        model.fit(X.values, y.values)\n",
    "\n",
    "        # recursive multi-step forecast\n",
    "        hist = s.copy()\n",
    "        preds = []\n",
    "        for step in range(horizon):\n",
    "            t_next = future_idx[step]\n",
    "\n",
    "            feats = {}\n",
    "            # lags\n",
    "            for l in range(1, L + 1):\n",
    "                feats[f\"lag_{l}\"] = float(hist.iloc[-l]) if len(hist) >= l else float(hist.iloc[-1])\n",
    "\n",
    "            # rolling (use available history)\n",
    "            feats[\"roll3\"] = float(hist.iloc[-3:].mean()) if len(hist) >= 3 else float(hist.mean())\n",
    "            feats[\"roll6\"] = float(hist.iloc[-6:].mean()) if len(hist) >= 6 else float(hist.mean())\n",
    "            feats[\"roll12\"] = float(hist.iloc[-12:].mean()) if len(hist) >= 12 else float(hist.mean())\n",
    "\n",
    "            if add_calendar:\n",
    "                mo = t_next.month  # 1..12\n",
    "                feats[\"mo_sin\"] = float(np.sin(2 * np.pi * mo / 12))\n",
    "                feats[\"mo_cos\"] = float(np.cos(2 * np.pi * mo / 12))\n",
    "\n",
    "            # align to training feature order\n",
    "            x_next = np.array([feats[k] for k in feature_order], dtype=float).reshape(1, -1)\n",
    "            yhat = float(model.predict(x_next)[0])\n",
    "\n",
    "            if col in nonneg_cols:\n",
    "                yhat = max(0.0, yhat)\n",
    "\n",
    "            preds.append(yhat)\n",
    "            hist.loc[t_next] = yhat  # extend history for next step\n",
    "\n",
    "        forecasts[col] = pd.Series(preds, index=future_idx)\n",
    "\n",
    "    out = pd.DataFrame({\"month\": future_idx})\n",
    "    for col in num_cols:\n",
    "        out[col] = forecasts[col].values\n",
    "    return out\n",
    "\n",
    "#--- Usage ---\n",
    "future_12_xgb = forecast_12_xgb(outcome_trend, horizon=12, use_gpu=True)\n",
    "print(future_12_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a3316922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n",
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\3472699208.py:36: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              series       RMSE  RMSE_baseline  RMSE_improvement_%  \\\n",
      "1     days_on_market  16.077661      19.283580           16.625121   \n",
      "0       price_change   0.077784       0.083718            7.087992   \n",
      "2  view_count_change   0.155686       0.233121           33.216397   \n",
      "\n",
      "      sMAPE_%  sMAPE_baseline_%  sMAPE_improvement_%      MASE  MASE_baseline  \n",
      "1   40.719116         45.972967            11.428132  1.035579       1.200344  \n",
      "0  156.035517        154.604815            -0.925393  1.201933       1.379221  \n",
      "2  145.932220        156.289588             6.627037  1.008859       1.492491  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samir\\AppData\\Local\\Temp\\ipykernel_9940\\2117917084.py:26: DeprecationWarning: is_period_dtype is deprecated and will be removed in a future version. Use `isinstance(dtype, pd.PeriodDtype)` instead\n",
      "  if pd.api.types.is_period_dtype(m):\n"
     ]
    }
   ],
   "source": [
    "# ---- Wrapper so your existing backtest_forecaster can call XGB ----\n",
    "def make_xgb_forecaster(use_gpu=True, max_lag=12, add_calendar=True, params=None,\n",
    "                        nonneg_cols=(\"days_on_market\",)):\n",
    "    \"\"\"\n",
    "    Returns a callable forecaster(train_df, horizon) -> forecast df,\n",
    "    which is exactly what backtest_forecaster expects.\n",
    "    \"\"\"\n",
    "    def _xgb_forecaster(train_df, horizon):\n",
    "        return forecast_12_xgb(\n",
    "            train_df,\n",
    "            horizon=horizon,\n",
    "            use_gpu=use_gpu,\n",
    "            max_lag=max_lag,\n",
    "            add_calendar=add_calendar,\n",
    "            params=params,\n",
    "            nonneg_cols=nonneg_cols,\n",
    "        )\n",
    "    return _xgb_forecaster\n",
    "\n",
    "# ---- Example usage with your existing backtest_forecaster ----\n",
    "xgb_fcst = make_xgb_forecaster(\n",
    "    use_gpu=True,\n",
    "    max_lag=12,\n",
    "    params={\"n_estimators\": 600, \"max_depth\": 5, \"learning_rate\": 0.05}\n",
    ")\n",
    "summary_xgb, by_h_xgb = backtest_forecaster(\n",
    "    outcome_trend,\n",
    "    forecaster=xgb_fcst,\n",
    "    horizon=12,\n",
    "    seasonality=12,\n",
    "    min_train=36,\n",
    "    step=1\n",
    ")\n",
    "print(summary_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "91d766c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBDegenerateClassifier(XGBClassifier):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.is_degenerate_ = None\n",
    "        self.degenerate_class_ = None\n",
    "\n",
    "    def fit_degen(self, X, y=None, **kwargs):\n",
    "        # If all target values are the same, skip training\n",
    "        if (sum(y) == len(y)) or (sum(y) == 0):\n",
    "            self.is_degenerate_ = True\n",
    "            self.degenerate_class_ = y[0]\n",
    "        else:\n",
    "            self.is_degenerate_ = False\n",
    "            self.fit(X, y, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict_degen(self, X):\n",
    "        if self.is_degenerate_:\n",
    "            return np.full((X.shape[0],), self.degenerate_class_)\n",
    "        else:\n",
    "            return self.predict(X)\n",
    "\n",
    "    def predict_proba_degen(self, X):\n",
    "        if self.is_degenerate_:\n",
    "            proba = np.zeros((X.shape[0], 2))\n",
    "            proba[:, self.degenerate_class_] = 1.0\n",
    "            return proba\n",
    "        else:\n",
    "            return self.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBDegenerateMultiClassifier(XGBClassifier):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.degenerate_classes_ = {}\n",
    "\n",
    "    def fit_degen(self, X, y=None, **kwargs):\n",
    "        # Check each class in the multi-label setting\n",
    "        for class_idx in range(y.shape[1]):\n",
    "            y_class = y[:, class_idx]\n",
    "            if (sum(y_class) == len(y_class)) or (sum(y_class) == 0):\n",
    "                self.degenerate_classes_[class_idx] = y_class[0]\n",
    "            else:\n",
    "                self.degenerate_classes_[class_idx] = None\n",
    "\n",
    "        # If any class is not degenerate, fit the model\n",
    "        if any(v is None for v in self.degenerate_classes_.values()):\n",
    "            self.fit(X, y, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def predict_degen(self, X):\n",
    "        if all(v is not None for v in self.degenerate_classes_.values()):\n",
    "            # All classes are degenerate\n",
    "            predictions = np.array([v for v in self.degenerate_classes_.values()])\n",
    "            return np.tile(predictions, (X.shape[0], 1))\n",
    "        else:\n",
    "            return self.predict(X)\n",
    "\n",
    "    def predict_proba_degen(self, X):\n",
    "        if all(v is not None for v in self.degenerate_classes_.values()):\n",
    "            # All classes are degenerate\n",
    "            proba = np.zeros((X.shape[0], len(self.degenerate_classes_), 2))\n",
    "            for class_idx, cls in self.degenerate_classes_.items():\n",
    "                proba[:, class_idx, cls] = 1.0\n",
    "            return proba\n",
    "        else:\n",
    "            return self.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22332a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(final_df, zip):\n",
    "    results, predictions, importances = [], [], []\n",
    "    training_sets, outcome_sets, inference_point = grab_training_records(final_df, zip)\n",
    "\n",
    "    for t in training_sets:\n",
    "        print(f\"\\nTraining model for {t} months prediction with {len(training_sets[t])} records\")\n",
    "        \n",
    "        predicted = [[] for _ in range(len(outcome_sets[t][0]))]\n",
    "        for i in range(len(training_sets[t])):\n",
    "            train_idx = np.ones((len(training_sets[t]),), dtype=bool)\n",
    "            train_idx[i] = False\n",
    "            X_train, X_val = training_sets[t][train_idx], training_sets[t][~train_idx]\n",
    "            \n",
    "            for outcome in range(len(outcome_sets[t][i])):\n",
    "                y_train, y_val = outcome_sets[t][train_idx][:, outcome], outcome_sets[t][~train_idx][:, outcome]\n",
    "                num_positives = np.sum(y_train)\n",
    "                \n",
    "                model = XGBDegenerateClassifier(eval_metric='logloss')\n",
    "                #print(f\"  Outcome {vars.outcomes[outcome]}: Training on {len(y_train)} records, count of Positives: {num_positives}\")\n",
    "                model.fit_degen(X_train, y_train)\n",
    "                preds = model.predict_proba_degen(X_val)\n",
    "                predicted[outcome].append(preds[0, 1])\n",
    "\n",
    "        predicted = np.array(predicted)\n",
    "\n",
    "        for outcome in range(len(outcome_sets[t][0])):\n",
    "            y_true = outcome_sets[t][:, outcome]\n",
    "            if np.all(y_true == 0) or np.all(y_true == 1):\n",
    "                auc_score = None  # undefined\n",
    "            else:\n",
    "                auc_score = np.round(roc_auc_score(y_true, predicted[outcome]), 4)\n",
    "            print(f\"Months Out: {t}, Outcome {vars.outcomes[outcome]}, AUC: {auc_score}\")\n",
    "            results.append([t, vars.outcomes[outcome], auc_score])\n",
    "\n",
    "            # Final Prediction\n",
    "            model = XGBDegenerateClassifier(eval_metric='logloss')\n",
    "            model.fit_degen(training_sets[t], outcome_sets[t][:, outcome])\n",
    "            \n",
    "            if np.all(y_true == 0) or np.all(y_true == 1):\n",
    "                importances.append([t, vars.outcomes[outcome], None])\n",
    "            else:\n",
    "                importances.append([t, vars.outcomes[outcome], model.feature_importances_])\n",
    "            final_pred = model.predict_proba_degen(inference_point)\n",
    "            predictions.append([t, vars.outcomes[outcome], final_pred[0, 1]])\n",
    "            print(f\"Months Out: {t}, Outcome {vars.outcomes[outcome]}, Final Prediction: {final_pred[0, 1]}\")\n",
    "    \n",
    "    return predicted, results, predictions, importances\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317622b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958eb975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_multiclass(final_df, zip):\n",
    "    results, predictions, importances = [], [], []\n",
    "    training_sets, outcome_sets, inference_point = grab_training_records(final_df, zip)\n",
    "\n",
    "    for t in training_sets:\n",
    "        print(f\"\\nTraining model for {t} months prediction with {len(training_sets[t])} records\")\n",
    "        \n",
    "        predicted = [[] for _ in range(len(outcome_sets[t][0]))]\n",
    "        for i in range(len(training_sets[t])):\n",
    "            train_idx = np.ones((len(training_sets[t]),), dtype=bool)\n",
    "            train_idx[i] = False\n",
    "            X_train, X_val = training_sets[t][train_idx], training_sets[t][~train_idx]\n",
    "            \n",
    "            for o in range(len(outcome_sets[t][i])//2):\n",
    "                o1 = 2*o\n",
    "                o2 = 2*o + 1\n",
    "                y_train = np.zeros((len(outcome_sets[t]), 3), dtype=int)\n",
    "                y_train[outcome_sets[t][:, o1] == 1, 0] = 1  # high risk\n",
    "                y_train[outcome_sets[t][:, o2] == 1, 2] = 1  # strong market\n",
    "                y_train[(y_train[:, 0] == 0) & (y_train[:, 2] == 0), 1] = 1  # neutral\n",
    "                y_val = np.zeros((1, 3), dtype=int)\n",
    "                if outcome_sets[t][i, o1] == 1:\n",
    "                    y_val[0, 0] = 1\n",
    "                elif outcome_sets[t][i, o2] == 1:\n",
    "                    y_val[0, 2] = 1\n",
    "                else:\n",
    "                    y_val[0, 1] = 1\n",
    "                \n",
    "                num_high_risk = y_train[:, 0].sum()\n",
    "                num_strong_market = y_train[:, 2].sum()\n",
    "\n",
    "                model = XGBDegenerateMultiClassifier(eval_metric='mlogloss')\n",
    "                model.fit_degen(X_train, y_train)\n",
    "                preds = model.predict_proba_degen(X_val)\n",
    "                \n",
    "            for outcome in range(len(outcome_sets[t][i])):\n",
    "                y_train, y_val = outcome_sets[t][train_idx][:, outcome], outcome_sets[t][~train_idx][:, outcome]\n",
    "                num_positives = np.sum(y_train)\n",
    "                \n",
    "                model = XGBDegenerateClassifier(eval_metric='logloss')\n",
    "                #print(f\"  Outcome {vars.outcomes[outcome]}: Training on {len(y_train)} records, count of Positives: {num_positives}\")\n",
    "                model.fit_degen(X_train, y_train)\n",
    "                preds = model.predict_proba_degen(X_val)\n",
    "                predicted[outcome].append(preds[0, 1])\n",
    "\n",
    "        predicted = np.array(predicted)\n",
    "\n",
    "        for outcome in range(len(outcome_sets[t][0])):\n",
    "            y_true = outcome_sets[t][:, outcome]\n",
    "            if np.all(y_true == 0) or np.all(y_true == 1):\n",
    "                auc_score = None  # undefined\n",
    "            else:\n",
    "                auc_score = np.round(roc_auc_score(y_true, predicted[outcome]), 4)\n",
    "            print(f\"Months Out: {t}, Outcome {vars.outcomes[outcome]}, AUC: {auc_score}\")\n",
    "            results.append([t, vars.outcomes[outcome], auc_score])\n",
    "\n",
    "            # Final Prediction\n",
    "            model = XGBDegenerateClassifier(eval_metric='logloss')\n",
    "            model.fit_degen(training_sets[t], outcome_sets[t][:, outcome])\n",
    "            \n",
    "            if np.all(y_true == 0) or np.all(y_true == 1):\n",
    "                importances.append([t, vars.outcomes[outcome], None])\n",
    "            else:\n",
    "                importances.append([t, vars.outcomes[outcome], model.feature_importances_])\n",
    "            final_pred = model.predict_proba_degen(inference_point)\n",
    "            predictions.append([t, vars.outcomes[outcome], final_pred[0, 1]])\n",
    "            print(f\"Months Out: {t}, Outcome {vars.outcomes[outcome]}, Final Prediction: {final_pred[0, 1]}\")\n",
    "    \n",
    "    return predicted, results, predictions, importances\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6697b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _is_degenerate(y):\n",
    "    return np.all(y == 0) or np.all(y == 1)\n",
    "\n",
    "def _train_with_dmatrix(X_train, y_train, X_val, y_val, *, use_gpu=True, verbose=False):\n",
    "    # Choose params (XGBoost â‰¥ 2.0 shown; for <2.0 use tree_method='gpu_hist', predictor='gpu_predictor')\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "    if use_gpu:\n",
    "        params[\"device\"] = \"cuda\"\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval   = xgb.DMatrix(X_val,   label=y_val)\n",
    "\n",
    "    evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "    booster = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=50 if verbose else False,\n",
    "    )\n",
    "    return booster\n",
    "\n",
    "def train_and_predict_dmatrix(final_df, zip, use_gpu=True, verbose=False):\n",
    "    results, predictions, importances = [], [], []\n",
    "    training_sets, outcome_sets, inference_point = grab_training_records(final_df, zip)\n",
    "\n",
    "    for t in training_sets:\n",
    "        print(f\"\\nTraining model for {t} months prediction with {len(training_sets[t])} records\")\n",
    "        n_outcomes = outcome_sets[t].shape[1]\n",
    "        predicted = [[] for _ in range(n_outcomes)]\n",
    "\n",
    "        # Leave-one-out CV\n",
    "        n = len(training_sets[t])\n",
    "        for i in range(n):\n",
    "            train_idx = np.ones((n,), dtype=bool)\n",
    "            train_idx[i] = False\n",
    "\n",
    "            X_train, X_val = training_sets[t][train_idx], training_sets[t][~train_idx]\n",
    "            for outcome in range(n_outcomes):\n",
    "                y_train = outcome_sets[t][train_idx][:, outcome]\n",
    "                y_val   = outcome_sets[t][~train_idx][:, outcome]\n",
    "\n",
    "                if _is_degenerate(y_train):\n",
    "                    # Degenerate: probability is the constant class\n",
    "                    p = float(y_train[0])\n",
    "                    predicted[outcome].append(p)\n",
    "                else:\n",
    "                    booster = _train_with_dmatrix(X_train, y_train, X_val, y_val, use_gpu=use_gpu, verbose=verbose)\n",
    "                    dval = xgb.DMatrix(X_val)\n",
    "                    p = booster.predict(dval, iteration_range=(0, booster.best_iteration + 1))[0]\n",
    "                    predicted[outcome].append(float(p))\n",
    "\n",
    "        predicted = np.array(predicted)\n",
    "\n",
    "        # Report AUCs and train final model for inference\n",
    "        X_all = training_sets[t]\n",
    "        d_infer = xgb.DMatrix(inference_point)\n",
    "\n",
    "        for outcome in range(n_outcomes):\n",
    "            y_true = outcome_sets[t][:, outcome]\n",
    "            auc_score = None if _is_degenerate(y_true) else np.round(roc_auc_score(y_true, predicted[outcome]), 4)\n",
    "            print(f\"Months Out: {t}, Outcome {vars.outcomes[outcome]}, AUC: {auc_score}\")\n",
    "            results.append([t, vars.outcomes[outcome], auc_score])\n",
    "\n",
    "            if _is_degenerate(y_true):\n",
    "                # no model, constant prediction\n",
    "                importances.append([t, vars.outcomes[outcome], None])\n",
    "                final_pred = float(y_true[0])\n",
    "            else:\n",
    "                # train on all data then predict inference point\n",
    "                dtrain_all = xgb.DMatrix(X_all, label=y_true)\n",
    "                booster = xgb.train(\n",
    "                    {\"objective\": \"binary:logistic\", \"eval_metric\": \"logloss\", \"tree_method\": \"hist\", **({\"device\": \"cuda\"} if use_gpu else {})},\n",
    "                    dtrain_all,\n",
    "                    num_boost_round= int(1.1 * (getattr(booster, \"best_iteration\", 100) or 100))  # simple heuristic\n",
    "                )\n",
    "                final_pred = float(booster.predict(d_infer)[0])\n",
    "\n",
    "                # Feature importances (gain)\n",
    "                # booster.get_score returns a dict {feature_name: importance}; if names are None it uses f0,f1,...\n",
    "                fmap = booster.get_score(importance_type=\"gain\")\n",
    "                # turn into a vector ordered by feature index (f0,f1,...)\n",
    "                if fmap:\n",
    "                    # Sort by feature index order\n",
    "                    keys = sorted(fmap.keys(), key=lambda k: int(k[1:]) if k.startswith(\"f\") else 0)\n",
    "                    import_vec = np.array([fmap[k] for k in keys], dtype=float)\n",
    "                else:\n",
    "                    import_vec = None\n",
    "                importances.append([t, vars.outcomes[outcome], import_vec])\n",
    "\n",
    "            predictions.append([t, vars.outcomes[outcome], final_pred])\n",
    "            print(f\"Months Out: {t}, Outcome {vars.outcomes[outcome]}, Final Prediction: {final_pred}\")\n",
    "\n",
    "    return predicted, results, predictions, importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "645bd3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for 1 months prediction with 91 records\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[185]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mzip\u001b[39m = \u001b[32m92620\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m predicted, results, predictions, importances = \u001b[43mtrain_and_predict_dmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[183]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mtrain_and_predict_dmatrix\u001b[39m\u001b[34m(final_df, zip, use_gpu, verbose)\u001b[39m\n\u001b[32m     51\u001b[39m     predicted[outcome].append(p)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     booster = \u001b[43m_train_with_dmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     dval = xgb.DMatrix(X_val)\n\u001b[32m     55\u001b[39m     p = booster.predict(dval, iteration_range=(\u001b[32m0\u001b[39m, booster.best_iteration + \u001b[32m1\u001b[39m))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[183]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36m_train_with_dmatrix\u001b[39m\u001b[34m(X_train, y_train, X_val, y_val, use_gpu, verbose)\u001b[39m\n\u001b[32m     15\u001b[39m dval   = xgb.DMatrix(X_val,   label=y_val)\n\u001b[32m     17\u001b[39m evals = [(dtrain, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m), (dval, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m booster = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m booster\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub\\realtor-analysis\\venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub\\realtor-analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub\\realtor-analysis\\venv\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "zip = 92620\n",
    "predicted, results, predictions, importances = train_and_predict_dmatrix(final_df, zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6fffb0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for 1 months prediction with 91 records\n",
      "Months Out: 1, Outcome high_risk_price_change, AUC: 0.603\n",
      "Months Out: 1, Outcome high_risk_price_change, Final Prediction: 0.037774939090013504\n",
      "Months Out: 1, Outcome strong_market_price_change, AUC: 0.3801\n",
      "Months Out: 1, Outcome strong_market_price_change, Final Prediction: 0.038898736238479614\n",
      "Months Out: 1, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 1, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 1, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 1, Outcome strong_market_days_on_market, Final Prediction: 0.01665658690035343\n",
      "Months Out: 1, Outcome high_risk_view_count_change, AUC: 0.7851\n",
      "Months Out: 1, Outcome high_risk_view_count_change, Final Prediction: 0.7286840677261353\n",
      "Months Out: 1, Outcome strong_market_view_count_change, AUC: 0.602\n",
      "Months Out: 1, Outcome strong_market_view_count_change, Final Prediction: 0.007675907574594021\n",
      "\n",
      "Training model for 2 months prediction with 90 records\n",
      "Months Out: 2, Outcome high_risk_price_change, AUC: 0.6351\n",
      "Months Out: 2, Outcome high_risk_price_change, Final Prediction: 0.4742906391620636\n",
      "Months Out: 2, Outcome strong_market_price_change, AUC: 0.6071\n",
      "Months Out: 2, Outcome strong_market_price_change, Final Prediction: 0.6196103096008301\n",
      "Months Out: 2, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 2, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 2, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 2, Outcome strong_market_days_on_market, Final Prediction: 0.017312802374362946\n",
      "Months Out: 2, Outcome high_risk_view_count_change, AUC: 0.6412\n",
      "Months Out: 2, Outcome high_risk_view_count_change, Final Prediction: 0.5910794734954834\n",
      "Months Out: 2, Outcome strong_market_view_count_change, AUC: 0.7484\n",
      "Months Out: 2, Outcome strong_market_view_count_change, Final Prediction: 0.05349436402320862\n",
      "\n",
      "Training model for 3 months prediction with 89 records\n",
      "Months Out: 3, Outcome high_risk_price_change, AUC: 0.7264\n",
      "Months Out: 3, Outcome high_risk_price_change, Final Prediction: 0.0859600380063057\n",
      "Months Out: 3, Outcome strong_market_price_change, AUC: 0.7025\n",
      "Months Out: 3, Outcome strong_market_price_change, Final Prediction: 0.7385321855545044\n",
      "Months Out: 3, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 3, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 3, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 3, Outcome strong_market_days_on_market, Final Prediction: 0.016722820699214935\n",
      "Months Out: 3, Outcome high_risk_view_count_change, AUC: 0.7389\n",
      "Months Out: 3, Outcome high_risk_view_count_change, Final Prediction: 0.914283812046051\n",
      "Months Out: 3, Outcome strong_market_view_count_change, AUC: 0.6218\n",
      "Months Out: 3, Outcome strong_market_view_count_change, Final Prediction: 0.052369292825460434\n",
      "\n",
      "Training model for 4 months prediction with 88 records\n",
      "Months Out: 4, Outcome high_risk_price_change, AUC: 0.809\n",
      "Months Out: 4, Outcome high_risk_price_change, Final Prediction: 0.09266205877065659\n",
      "Months Out: 4, Outcome strong_market_price_change, AUC: 0.8002\n",
      "Months Out: 4, Outcome strong_market_price_change, Final Prediction: 0.9752877354621887\n",
      "Months Out: 4, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 4, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 4, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 4, Outcome strong_market_days_on_market, Final Prediction: 0.016968462616205215\n",
      "Months Out: 4, Outcome high_risk_view_count_change, AUC: 0.8164\n",
      "Months Out: 4, Outcome high_risk_view_count_change, Final Prediction: 0.25605085492134094\n",
      "Months Out: 4, Outcome strong_market_view_count_change, AUC: 0.721\n",
      "Months Out: 4, Outcome strong_market_view_count_change, Final Prediction: 0.23390239477157593\n",
      "\n",
      "Training model for 5 months prediction with 87 records\n",
      "Months Out: 5, Outcome high_risk_price_change, AUC: 0.8258\n",
      "Months Out: 5, Outcome high_risk_price_change, Final Prediction: 0.4177681803703308\n",
      "Months Out: 5, Outcome strong_market_price_change, AUC: 0.8791\n",
      "Months Out: 5, Outcome strong_market_price_change, Final Prediction: 0.9270128607749939\n",
      "Months Out: 5, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 5, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 5, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 5, Outcome strong_market_days_on_market, Final Prediction: 0.016789156943559647\n",
      "Months Out: 5, Outcome high_risk_view_count_change, AUC: 0.9013\n",
      "Months Out: 5, Outcome high_risk_view_count_change, Final Prediction: 0.7374194860458374\n",
      "Months Out: 5, Outcome strong_market_view_count_change, AUC: 0.8152\n",
      "Months Out: 5, Outcome strong_market_view_count_change, Final Prediction: 0.19759716093540192\n",
      "\n",
      "Training model for 6 months prediction with 86 records\n",
      "Months Out: 6, Outcome high_risk_price_change, AUC: 0.87\n",
      "Months Out: 6, Outcome high_risk_price_change, Final Prediction: 0.7889007925987244\n",
      "Months Out: 6, Outcome strong_market_price_change, AUC: 0.7984\n",
      "Months Out: 6, Outcome strong_market_price_change, Final Prediction: 0.3311297595500946\n",
      "Months Out: 6, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 6, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 6, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 6, Outcome strong_market_days_on_market, Final Prediction: 0.01704106666147709\n",
      "Months Out: 6, Outcome high_risk_view_count_change, AUC: 0.7937\n",
      "Months Out: 6, Outcome high_risk_view_count_change, Final Prediction: 0.4373959004878998\n",
      "Months Out: 6, Outcome strong_market_view_count_change, AUC: 0.8874\n",
      "Months Out: 6, Outcome strong_market_view_count_change, Final Prediction: 0.4882740080356598\n",
      "\n",
      "Training model for 7 months prediction with 85 records\n",
      "Months Out: 7, Outcome high_risk_price_change, AUC: 0.8289\n",
      "Months Out: 7, Outcome high_risk_price_change, Final Prediction: 0.5948420166969299\n",
      "Months Out: 7, Outcome strong_market_price_change, AUC: 0.8361\n",
      "Months Out: 7, Outcome strong_market_price_change, Final Prediction: 0.12671233713626862\n",
      "Months Out: 7, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 7, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 7, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 7, Outcome strong_market_days_on_market, Final Prediction: 0.017751365900039673\n",
      "Months Out: 7, Outcome high_risk_view_count_change, AUC: 0.8728\n",
      "Months Out: 7, Outcome high_risk_view_count_change, Final Prediction: 0.18266762793064117\n",
      "Months Out: 7, Outcome strong_market_view_count_change, AUC: 0.869\n",
      "Months Out: 7, Outcome strong_market_view_count_change, Final Prediction: 0.42143329977989197\n",
      "\n",
      "Training model for 8 months prediction with 84 records\n",
      "Months Out: 8, Outcome high_risk_price_change, AUC: 0.8547\n",
      "Months Out: 8, Outcome high_risk_price_change, Final Prediction: 0.15781019628047943\n",
      "Months Out: 8, Outcome strong_market_price_change, AUC: 0.7832\n",
      "Months Out: 8, Outcome strong_market_price_change, Final Prediction: 0.10808970779180527\n",
      "Months Out: 8, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 8, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 8, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 8, Outcome strong_market_days_on_market, Final Prediction: 0.0175685603171587\n",
      "Months Out: 8, Outcome high_risk_view_count_change, AUC: 0.794\n",
      "Months Out: 8, Outcome high_risk_view_count_change, Final Prediction: 0.07655785977840424\n",
      "Months Out: 8, Outcome strong_market_view_count_change, AUC: 0.7426\n",
      "Months Out: 8, Outcome strong_market_view_count_change, Final Prediction: 0.6623194217681885\n",
      "\n",
      "Training model for 9 months prediction with 83 records\n",
      "Months Out: 9, Outcome high_risk_price_change, AUC: 0.8364\n",
      "Months Out: 9, Outcome high_risk_price_change, Final Prediction: 0.05331108346581459\n",
      "Months Out: 9, Outcome strong_market_price_change, AUC: 0.7437\n",
      "Months Out: 9, Outcome strong_market_price_change, Final Prediction: 0.375136137008667\n",
      "Months Out: 9, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 9, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 9, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 9, Outcome strong_market_days_on_market, Final Prediction: 0.01879250817000866\n",
      "Months Out: 9, Outcome high_risk_view_count_change, AUC: 0.8655\n",
      "Months Out: 9, Outcome high_risk_view_count_change, Final Prediction: 0.09829793125391006\n",
      "Months Out: 9, Outcome strong_market_view_count_change, AUC: 0.8345\n",
      "Months Out: 9, Outcome strong_market_view_count_change, Final Prediction: 0.935822069644928\n",
      "\n",
      "Training model for 10 months prediction with 82 records\n",
      "Months Out: 10, Outcome high_risk_price_change, AUC: 0.9301\n",
      "Months Out: 10, Outcome high_risk_price_change, Final Prediction: 0.03366674482822418\n",
      "Months Out: 10, Outcome strong_market_price_change, AUC: 0.8288\n",
      "Months Out: 10, Outcome strong_market_price_change, Final Prediction: 0.6734093427658081\n",
      "Months Out: 10, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 10, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 10, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 10, Outcome strong_market_days_on_market, Final Prediction: 0.019099561497569084\n",
      "Months Out: 10, Outcome high_risk_view_count_change, AUC: 0.8527\n",
      "Months Out: 10, Outcome high_risk_view_count_change, Final Prediction: 0.12929511070251465\n",
      "Months Out: 10, Outcome strong_market_view_count_change, AUC: 0.7757\n",
      "Months Out: 10, Outcome strong_market_view_count_change, Final Prediction: 0.16023221611976624\n",
      "\n",
      "Training model for 11 months prediction with 81 records\n",
      "Months Out: 11, Outcome high_risk_price_change, AUC: 0.8841\n",
      "Months Out: 11, Outcome high_risk_price_change, Final Prediction: 0.3111867606639862\n",
      "Months Out: 11, Outcome strong_market_price_change, AUC: 0.8951\n",
      "Months Out: 11, Outcome strong_market_price_change, Final Prediction: 0.6373581886291504\n",
      "Months Out: 11, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 11, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 11, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 11, Outcome strong_market_days_on_market, Final Prediction: 0.019417064264416695\n",
      "Months Out: 11, Outcome high_risk_view_count_change, AUC: 0.837\n",
      "Months Out: 11, Outcome high_risk_view_count_change, Final Prediction: 0.8258910775184631\n",
      "Months Out: 11, Outcome strong_market_view_count_change, AUC: 0.8389\n",
      "Months Out: 11, Outcome strong_market_view_count_change, Final Prediction: 0.32376378774642944\n",
      "\n",
      "Training model for 12 months prediction with 80 records\n",
      "Months Out: 12, Outcome high_risk_price_change, AUC: 0.9204\n",
      "Months Out: 12, Outcome high_risk_price_change, Final Prediction: 0.0914609432220459\n",
      "Months Out: 12, Outcome strong_market_price_change, AUC: 0.8814\n",
      "Months Out: 12, Outcome strong_market_price_change, Final Prediction: 0.38886281847953796\n",
      "Months Out: 12, Outcome high_risk_days_on_market, AUC: None\n",
      "Months Out: 12, Outcome high_risk_days_on_market, Final Prediction: 0.0\n",
      "Months Out: 12, Outcome strong_market_days_on_market, AUC: 1.0\n",
      "Months Out: 12, Outcome strong_market_days_on_market, Final Prediction: 0.019233867526054382\n",
      "Months Out: 12, Outcome high_risk_view_count_change, AUC: 0.8259\n",
      "Months Out: 12, Outcome high_risk_view_count_change, Final Prediction: 0.4209781587123871\n",
      "Months Out: 12, Outcome strong_market_view_count_change, AUC: 0.779\n",
      "Months Out: 12, Outcome strong_market_view_count_change, Final Prediction: 0.373576819896698\n"
     ]
    }
   ],
   "source": [
    "zip = 92620\n",
    "predicted, results, predictions, importances = train_and_predict(final_df, zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce0eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
